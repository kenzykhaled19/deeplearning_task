{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY6xJzAG8aS_"
      },
      "source": [
        "**Part 0: Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hXYbVwnFzVV2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "InMWcOmNzeUI",
        "outputId": "fc2411b2-bf2e-409a-9c85-2abec57ea061"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
              "0   25    Private  226802          11th              7       Never-married   \n",
              "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
              "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
              "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
              "4   18        NaN  103497  Some-college             10       Never-married   \n",
              "\n",
              "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
              "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
              "1    Farming-fishing      Husband  White    Male             0             0   \n",
              "2    Protective-serv      Husband  White    Male             0             0   \n",
              "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
              "4                NaN    Own-child  White  Female             0             0   \n",
              "\n",
              "   hours-per-week native-country  class  \n",
              "0              40  United-States  <=50K  \n",
              "1              50  United-States  <=50K  \n",
              "2              40  United-States   >50K  \n",
              "3              40  United-States   >50K  \n",
              "4              30  United-States  <=50K  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e4a8e4c-8408-432e-9cd3-592e3a0fa44d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>103497</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e4a8e4c-8408-432e-9cd3-592e3a0fa44d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e4a8e4c-8408-432e-9cd3-592e3a0fa44d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e4a8e4c-8408-432e-9cd3-592e3a0fa44d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-74d229c9-4203-4778-84d9-1d68055d47bf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74d229c9-4203-4778-84d9-1d68055d47bf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-74d229c9-4203-4778-84d9-1d68055d47bf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 48842,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 17,\n        \"max\": 90,\n        \"num_unique_values\": 74,\n        \"samples\": [\n          18,\n          74,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Local-gov\",\n          \"Self-emp-inc\",\n          \"Private\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fnlwgt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105604,\n        \"min\": 12285,\n        \"max\": 1490400,\n        \"num_unique_values\": 28523,\n        \"samples\": [\n          171041,\n          20296,\n          263896\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"11th\",\n          \"HS-grad\",\n          \"Prof-school\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education-num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          7,\n          9,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital-status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Never-married\",\n          \"Married-civ-spouse\",\n          \"Married-spouse-absent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"occupation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Sales\",\n          \"Transport-moving\",\n          \"Machine-op-inspct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relationship\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Own-child\",\n          \"Husband\",\n          \"Other-relative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"race\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"White\",\n          \"Amer-Indian-Eskimo\",\n          \"Asian-Pac-Islander\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-gain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7452,\n        \"min\": 0,\n        \"max\": 99999,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          4064,\n          4787\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capital-loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 403,\n        \"min\": 0,\n        \"max\": 4356,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          2238,\n          1564\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hours-per-week\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1,\n        \"max\": 99,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          9,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"native-country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"Canada\",\n          \"South\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \">50K\",\n          \"<=50K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "adult=fetch_openml(name=\"adult\",version=2,as_frame=True)\n",
        "data=adult.frame\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UKoW6Yt9ze1g"
      },
      "outputs": [],
      "source": [
        "x=data.drop(columns=\"class\")\n",
        "y=data['class']  #dividing my data into features and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJQtb0fBzn7o",
        "outputId": "db1f8e00-0e6b-46c8-c2eb-22f217c7f91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34187\n",
            "7327\n",
            "7328\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#70=> train 15=>test 15=>validation\n",
        "x_train_valid,x_test,y_train_valid,y_test=train_test_split(x,y,test_size=0.15,shuffle=True)  #Train =>85% test=>15%\n",
        "#x,y valid=>15/85\n",
        "x_train,x_valid,y_train,y_valid=train_test_split(x_train_valid,y_train_valid,test_size=0.1765,shuffle=True)\n",
        "print(len(y_train))\n",
        "print(len(y_test))\n",
        "print(len(y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onGpnOGSzrjz",
        "outputId": "f01f5ace-e3b7-4f08-e91d-323ee930d5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype   \n",
            "---  ------          --------------  -----   \n",
            " 0   age             48842 non-null  int64   \n",
            " 1   workclass       46043 non-null  category\n",
            " 2   fnlwgt          48842 non-null  int64   \n",
            " 3   education       48842 non-null  category\n",
            " 4   education-num   48842 non-null  int64   \n",
            " 5   marital-status  48842 non-null  category\n",
            " 6   occupation      46033 non-null  category\n",
            " 7   relationship    48842 non-null  category\n",
            " 8   race            48842 non-null  category\n",
            " 9   sex             48842 non-null  category\n",
            " 10  capital-gain    48842 non-null  int64   \n",
            " 11  capital-loss    48842 non-null  int64   \n",
            " 12  hours-per-week  48842 non-null  int64   \n",
            " 13  native-country  47985 non-null  category\n",
            " 14  class           48842 non-null  category\n",
            "dtypes: category(9), int64(6)\n",
            "memory usage: 2.7 MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj9EpIJbzvLj",
        "outputId": "c5ff9d66-9bf4-4ffb-ca1b-258461ea1d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['workclass', 'education', 'marital-status', 'occupation',\n",
            "       'relationship', 'race', 'sex', 'native-country'],\n",
            "      dtype='object')\n",
            "Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
            "       'hours-per-week'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "catagorical_feature=x_train.select_dtypes(include=[\"category\"]).columns\n",
        "numerical_feature=x_train.select_dtypes(exclude=[\"category\"]).columns\n",
        "\n",
        "print(catagorical_feature) #==>label encoding\n",
        "print(numerical_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rkmPkNxUzyA_"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder , StandardScaler ,LabelEncoder\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\") #ensures that won’t crash if it encounters a new unseen category.\n",
        "numerical_transformer=StandardScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pwfRkoQYz20n"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numerical_transformer, numerical_feature), # make numerical_transformer for each numerical fearture\n",
        "        (\"cat\", categorical_transformer, catagorical_feature) #same thing\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train_proc = preprocessor.fit_transform(x_train)  #fit on train because it learn here\n",
        "X_valid_proc = preprocessor.transform(x_valid) #apply scale or encoder in validation and test\n",
        "X_test_proc = preprocessor.transform(x_test)\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train_enc = encoder.fit_transform(y_train)\n",
        "y_valid_enc = encoder.transform(y_valid)\n",
        "y_test_enc = encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "QLitc3AZz54x",
        "outputId": "f59329c5-9b8b-4d56-d45c-57f6b4fa4039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#logistic regression ==>machine learing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_proc ,y_train_enc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHJs6f0_z-wZ",
        "outputId": "b4ed0737-9058-4c7b-f319-27cd1787e058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of train: $85.29%\n",
            "accuracy of validation: $85.22%\n",
            "accuracy of test: $85.31%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_acc_log = accuracy_score(y_train_enc, log_reg.predict(X_train_proc))\n",
        "valid_acc_log = accuracy_score(y_valid_enc, log_reg.predict(X_valid_proc))\n",
        "test_acc_log = accuracy_score(y_test_enc, log_reg.predict(X_test_proc))\n",
        "print(f\"accuracy of train: ${train_acc_log *100:0.2f}%\")\n",
        "print(f\"accuracy of validation: ${valid_acc_log*100:0.2f}%\")\n",
        "print(f\"accuracy of test: ${test_acc_log*100:0.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F22kDy3k0CVG",
        "outputId": "989f807a-391c-4269-952e-5fee2a807177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1Zg-h-l50Iri"
      },
      "outputs": [],
      "source": [
        "# Deep Neural Network==>deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEMs8nhl0I9q",
        "outputId": "29963741-784e-496a-8bac-799a15d50a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3406 - val_accuracy: 0.8521 - val_loss: 0.3202\n",
            "Epoch 2/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3154 - val_accuracy: 0.8555 - val_loss: 0.3160\n",
            "Epoch 3/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3032 - val_accuracy: 0.8536 - val_loss: 0.3150\n",
            "Epoch 4/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.2966 - val_accuracy: 0.8511 - val_loss: 0.3174\n",
            "Epoch 5/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3071 - val_accuracy: 0.8543 - val_loss: 0.3131\n",
            "Epoch 6/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.3021 - val_accuracy: 0.8480 - val_loss: 0.3244\n",
            "Epoch 7/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.2981 - val_accuracy: 0.8526 - val_loss: 0.3139\n",
            "Epoch 8/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - accuracy: 0.8599 - loss: 0.2980 - val_accuracy: 0.8536 - val_loss: 0.3166\n",
            "Epoch 9/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.2989 - val_accuracy: 0.8541 - val_loss: 0.3129\n",
            "Epoch 10/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.2946 - val_accuracy: 0.8560 - val_loss: 0.3216\n",
            "Training Stochastic Gradient Descent (SGD) completed after 10 epochs.\n"
          ]
        }
      ],
      "source": [
        "#optimization using Stochastic Gradient Descent (SGD)\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "sgd_model=Sequential()\n",
        "sgd_model.add(Dense(64,activation=\"relu\",input_shape=(X_train_proc.shape[1],)))\n",
        "sgd_model.add(Dense(32,activation=\"relu\"))\n",
        "sgd_model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "optimizer = SGD(learning_rate=0.01)\n",
        "sgd_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "sgd_model_fitting=sgd_model.fit(X_train_proc,y_train_enc,epochs=10,validation_data=(X_valid_proc,y_valid_enc),batch_size=1)\n",
        "print(f\"Training Stochastic Gradient Descent (SGD) completed after {len(sgd_model_fitting.epoch)} epochs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HYkDiOp30dxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f7f43d-f999-4707-8c8f-daf55c214b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8237 - loss: 0.3744 - val_accuracy: 0.8532 - val_loss: 0.3193\n",
            "Epoch 2/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3089 - val_accuracy: 0.8511 - val_loss: 0.3218\n",
            "Epoch 3/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3062 - val_accuracy: 0.8559 - val_loss: 0.3140\n",
            "Epoch 4/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3006 - val_accuracy: 0.8569 - val_loss: 0.3142\n",
            "Epoch 5/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.3037 - val_accuracy: 0.8548 - val_loss: 0.3133\n",
            "Epoch 6/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3041 - val_accuracy: 0.8528 - val_loss: 0.3152\n",
            "Epoch 7/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3005 - val_accuracy: 0.8548 - val_loss: 0.3162\n",
            "Epoch 8/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3003 - val_accuracy: 0.8547 - val_loss: 0.3135\n",
            "Epoch 9/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8603 - loss: 0.2992 - val_accuracy: 0.8530 - val_loss: 0.3145\n",
            "Epoch 10/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8609 - loss: 0.2959 - val_accuracy: 0.8551 - val_loss: 0.3153\n",
            "Training SGD with Momentum completed after 10 epochs.\n"
          ]
        }
      ],
      "source": [
        "#optimization using SGD with Momentum\n",
        "moment_model=Sequential()\n",
        "moment_model.add(Dense(64,activation=\"relu\",input_shape=(X_train_proc.shape[1],)))\n",
        "moment_model.add(Dense(32,activation=\"relu\"))\n",
        "moment_model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "optimizer = SGD(learning_rate=0.01,momentum=0.9)#highly depeneding on past gardients\n",
        "moment_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "moment_model_fitting=moment_model.fit(X_train_proc,y_train_enc,epochs=10,validation_data=(X_valid_proc,y_valid_enc))\n",
        "print(f\"Training SGD with Momentum completed after {len(moment_model_fitting.epoch)} epochs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZdjYCsb2KuU",
        "outputId": "4de9f364-e43e-44f8-fe17-0d1c2eccc1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3361 - val_accuracy: 0.8519 - val_loss: 0.3157\n",
            "Epoch 2/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3070 - val_accuracy: 0.8571 - val_loss: 0.3142\n",
            "Epoch 3/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3021 - val_accuracy: 0.8555 - val_loss: 0.3160\n",
            "Epoch 4/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.2980 - val_accuracy: 0.8552 - val_loss: 0.3107\n",
            "Epoch 5/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.2926 - val_accuracy: 0.8562 - val_loss: 0.3207\n",
            "Epoch 6/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.2909 - val_accuracy: 0.8548 - val_loss: 0.3225\n",
            "Epoch 7/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.2905 - val_accuracy: 0.8548 - val_loss: 0.3182\n",
            "Epoch 8/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.2849 - val_accuracy: 0.8603 - val_loss: 0.3180\n",
            "Epoch 9/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.2793 - val_accuracy: 0.8573 - val_loss: 0.3183\n",
            "Epoch 10/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8689 - loss: 0.2786 - val_accuracy: 0.8573 - val_loss: 0.3222\n",
            "Training using Adam completed after 10 epochs.\n"
          ]
        }
      ],
      "source": [
        "#optimization using Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "adam_model=Sequential()\n",
        "adam_model.add(Dense(64,activation=\"relu\",input_shape=(X_train_proc.shape[1],)))\n",
        "adam_model.add(Dense(32,activation=\"relu\"))\n",
        "adam_model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "adam_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "adam_model_fitting=adam_model.fit(X_train_proc,y_train_enc,epochs=10,validation_data=(X_valid_proc,y_valid_enc))\n",
        "print(f\"Training using Adam completed after {len(adam_model_fitting.epoch)} epochs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmF7wYEg8sAS"
      },
      "source": [
        "##Compare the training and validation accuracy for each optimizer.?\n",
        "SGD\n",
        "\n",
        "- Training accuracy started around ~ 77% until reached 86%.\n",
        "\n",
        "- Validation accuracy started around in range of 85%.\n",
        "\n",
        "- Learning happens but it is slow.\n",
        "\n",
        "SGD + Momentum\n",
        "\n",
        "- Training accuracy started a bit higher ~ %82 until reached ~ 86%.\n",
        "\n",
        "- Validation accuracy stable around ~ 0.85–0.856.\n",
        "\n",
        "- Faster than plain SGD.\n",
        "\n",
        "Adam\n",
        "\n",
        "- Training accuracy started high (~ 84%) until reached ~ 87%.\n",
        "\n",
        "- Validation accuracy reached ~ 86% (highest of all).\n",
        "\n",
        "- Very fast learning from the first epochs.\n",
        "##Which converges faster? Which generalizes better?\n",
        "\n",
        "Fastest convergence => Adam (high accuracy among of them).\n",
        "\n",
        "Best generalization (validation$test accuracy) => Adam, since validation accuracy is slightly higher (~ 86%).\n",
        "\n",
        "##Why is Adam often better than SGD?\n",
        "\n",
        "SGD: Uses the same learning rate for all weights moves step by step with the same pace in every direction. This makes it slower or oscillating around the solution.\n",
        "\n",
        "Adam: Smarter one it also combines\n",
        "\n",
        "- Momentum (keeps track of past directions to speed up).\n",
        "\n",
        "- Uses RMSprop which is Adaptive learning rates (each weight can move with a different step size depending on its updates).\n",
        "\n",
        "so it became Faster training + often better validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K2Te7MJZAfcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78ae667-31cd-4e1f-90f5-c3e56f3ea498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.3621 - val_accuracy: 0.8186 - val_loss: 0.4111\n",
            "Epoch 2/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.3408 - val_accuracy: 0.8519 - val_loss: 0.3338\n",
            "Epoch 3/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - accuracy: 0.8498 - loss: 0.3315 - val_accuracy: 0.8442 - val_loss: 0.4338\n",
            "Epoch 4/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3417 - val_accuracy: 0.8530 - val_loss: 0.3652\n",
            "Epoch 5/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - accuracy: 0.8543 - loss: 0.3288 - val_accuracy: 0.8470 - val_loss: 0.3472\n",
            "Epoch 6/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.3384 - val_accuracy: 0.8463 - val_loss: 0.3518\n",
            "Epoch 7/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3272 - val_accuracy: 0.8506 - val_loss: 0.3354\n",
            "Epoch 8/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.3296 - val_accuracy: 0.8506 - val_loss: 0.3440\n",
            "Epoch 9/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.3248 - val_accuracy: 0.8287 - val_loss: 0.3398\n",
            "Epoch 10/10\n",
            "\u001b[1m34187/34187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3289 - val_accuracy: 0.8425 - val_loss: 0.3541\n",
            "Training with Adam and batch_size=1 completed.\n"
          ]
        }
      ],
      "source": [
        "#training the data with different batch size using ADam optimizer\n",
        "# Adam with batch size = 1\n",
        "adam_model_bs1 = Sequential()\n",
        "adam_model_bs1.add(Dense(64, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "adam_model_bs1.add(Dense(32, activation=\"relu\"))\n",
        "adam_model_bs1.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "adam_model_bs1.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                       loss=\"binary_crossentropy\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "\n",
        "adam_model_bs1_fitting = adam_model_bs1.fit(X_train_proc, y_train_enc,epochs=10,batch_size=1,validation_data=(X_valid_proc, y_valid_enc))\n",
        "print(\"Training with Adam and batch_size=1 completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q4RKv5hn8zZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacb896d-4f52-4461-c52d-e1c034e5db5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.3436 - val_accuracy: 0.8530 - val_loss: 0.3197\n",
            "Epoch 2/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3104 - val_accuracy: 0.8558 - val_loss: 0.3145\n",
            "Epoch 3/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3051 - val_accuracy: 0.8562 - val_loss: 0.3146\n",
            "Epoch 4/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.3001 - val_accuracy: 0.8549 - val_loss: 0.3152\n",
            "Epoch 5/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.2963 - val_accuracy: 0.8552 - val_loss: 0.3149\n",
            "Epoch 6/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.2946 - val_accuracy: 0.8511 - val_loss: 0.3177\n",
            "Epoch 7/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.2912 - val_accuracy: 0.8529 - val_loss: 0.3209\n",
            "Epoch 8/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.2818 - val_accuracy: 0.8537 - val_loss: 0.3264\n",
            "Epoch 9/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.2845 - val_accuracy: 0.8525 - val_loss: 0.3263\n",
            "Epoch 10/10\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.2782 - val_accuracy: 0.8563 - val_loss: 0.3221\n",
            "Training with Adam and batch_size=32 completed.\n"
          ]
        }
      ],
      "source": [
        "# Adam with batch size = 32\n",
        "adam_model_bs32 = Sequential()\n",
        "adam_model_bs32.add(Dense(64, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "adam_model_bs32.add(Dense(32, activation=\"relu\"))\n",
        "adam_model_bs32.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "adam_model_bs32.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                        loss=\"binary_crossentropy\",\n",
        "                        metrics=[\"accuracy\"])\n",
        "\n",
        "adam_model_bs32_fitting = adam_model_bs32.fit(\n",
        "    X_train_proc, y_train_enc,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_valid_proc, y_valid_enc)\n",
        ")\n",
        "print(\"Training with Adam and batch_size=32 completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam with batch size = 128\n",
        "adam_model_bs128 = Sequential()\n",
        "adam_model_bs128.add(Dense(64, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "adam_model_bs128.add(Dense(32, activation=\"relu\"))\n",
        "adam_model_bs128.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "adam_model_bs128.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                        loss=\"binary_crossentropy\",\n",
        "                        metrics=[\"accuracy\"])\n",
        "\n",
        "adam_model_bs128_fitting = adam_model_bs128.fit(\n",
        "    X_train_proc, y_train_enc,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid_proc, y_valid_enc)\n",
        ")\n",
        "print(\"Training with Adam and batch_size=128 completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mr-qLQE1DZK",
        "outputId": "b8f3d452-6a3b-4bbc-8c3c-537c017b5a86"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3540 - val_accuracy: 0.8562 - val_loss: 0.3161\n",
            "Epoch 2/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.3047 - val_accuracy: 0.8549 - val_loss: 0.3132\n",
            "Epoch 3/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.3044 - val_accuracy: 0.8537 - val_loss: 0.3147\n",
            "Epoch 4/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.2991 - val_accuracy: 0.8564 - val_loss: 0.3158\n",
            "Epoch 5/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.2928 - val_accuracy: 0.8562 - val_loss: 0.3114\n",
            "Epoch 6/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8646 - loss: 0.2882 - val_accuracy: 0.8538 - val_loss: 0.3177\n",
            "Epoch 7/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.2815 - val_accuracy: 0.8541 - val_loss: 0.3192\n",
            "Epoch 8/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.2822 - val_accuracy: 0.8548 - val_loss: 0.3182\n",
            "Epoch 9/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.2779 - val_accuracy: 0.8537 - val_loss: 0.3207\n",
            "Epoch 10/10\n",
            "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8711 - loss: 0.2730 - val_accuracy: 0.8518 - val_loss: 0.3248\n",
            "Training with Adam and batch_size=128 completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam with batch size = 1024\n",
        "adam_model_bs1024 = Sequential()\n",
        "adam_model_bs1024.add(Dense(64, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "adam_model_bs1024.add(Dense(32, activation=\"relu\"))\n",
        "adam_model_bs1024.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "adam_model_bs1024.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                        loss=\"binary_crossentropy\",\n",
        "                        metrics=[\"accuracy\"])\n",
        "\n",
        "adam_model_bs1024_fitting = adam_model_bs1024.fit(\n",
        "    X_train_proc, y_train_enc,\n",
        "    epochs=10,\n",
        "    batch_size=1024,\n",
        "    validation_data=(X_valid_proc, y_valid_enc)\n",
        ")\n",
        "print(\"Training with Adam and batch_size=1024 completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVjzdbRS1LvM",
        "outputId": "2e6a99e4-e3fc-4a42-c0d4-131c1028af55"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7693 - loss: 0.4342 - val_accuracy: 0.8534 - val_loss: 0.3218\n",
            "Epoch 2/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8552 - loss: 0.3104 - val_accuracy: 0.8536 - val_loss: 0.3152\n",
            "Epoch 3/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8582 - loss: 0.3052 - val_accuracy: 0.8552 - val_loss: 0.3140\n",
            "Epoch 4/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8609 - loss: 0.2984 - val_accuracy: 0.8506 - val_loss: 0.3183\n",
            "Epoch 5/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8606 - loss: 0.2979 - val_accuracy: 0.8532 - val_loss: 0.3164\n",
            "Epoch 6/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8644 - loss: 0.2926 - val_accuracy: 0.8553 - val_loss: 0.3146\n",
            "Epoch 7/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8678 - loss: 0.2847 - val_accuracy: 0.8532 - val_loss: 0.3181\n",
            "Epoch 8/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8663 - loss: 0.2910 - val_accuracy: 0.8533 - val_loss: 0.3186\n",
            "Epoch 9/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8691 - loss: 0.2814 - val_accuracy: 0.8551 - val_loss: 0.3226\n",
            "Epoch 10/10\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8654 - loss: 0.2837 - val_accuracy: 0.8502 - val_loss: 0.3250\n",
            "Training with Adam and batch_size=1024 completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Training speed:*\n",
        "\n",
        "- Batch size =1 => Very slow because the model updates weights after every single sample.That means too many updates and much longer training time.\n",
        "\n",
        "- Batch size = 32 & 128 => Much faster, since the model processes more samples at once (mini-batch training)and accuracy is almost high 87%.\n",
        "\n",
        "- Batch size =1024 => Even faster per epoch (fewer updates), but sometimes less accurate updates.\n",
        "\n",
        "*Validation accuracy:*\n",
        "\n",
        "- Batch size = 1: Validation accuracy fluctuates a lot which is unstable. Sometimes good, sometimes drops.\n",
        "\n",
        "- Batch size = 32: Stable and high validation accuracy. Often gives the best balance.\n",
        "\n",
        "- Batch size = 128: Still good, but sometimes slightly less stable than 32.\n",
        "\n",
        "- Batch size = 1024: Validation accuracy can drop, because updates are too poor and the model may not capture enough detail.\n",
        "\n",
        "\n",
        "*Test accuracy:*\n",
        "\n",
        "Small batch sizes (1, 32) → Usually generalize better meaning they perform well on unseen test data.\n",
        "\n",
        "Large batch sizes (1024) → Sometimes test accuracy is worse because the model overfits the training data patterns and doesn’t generalize well.\n",
        "\n",
        "*Generalization ability:*\n",
        "\n",
        "- Best generalization is usually with batch size = 32 or 128.\n",
        "\n",
        "- Batch size = 1 generalizes okay but is very noisy and inefficient.\n",
        "\n",
        "- Batch size = 1024 generalizes poorly because updates are too smooth and the model doesn’t learn enough.\n",
        "#Which batch size leads to the noisiest gradient updates?\n",
        "Batch size = 1 =>Because every update depends on only one sample, the gradient jumps around a lot = very noisy.\n",
        "\n",
        "#Which batch size generalizes better and why?\n",
        "\n",
        "Batch size = 32 & 128 =>Because:\n",
        "\n",
        "- It balances between noise and stability. (mini batch gradient descent)\n"
      ],
      "metadata": {
        "id": "6e5yiyrUD8Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Overfitting and Regularization\n",
        "large_model = Sequential()\n",
        "large_model.add(Dense(256, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "large_model.add(Dense(128, activation=\"relu\"))\n",
        "large_model.add(Dense(64, activation=\"relu\"))\n",
        "large_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "large_model.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "history_large = large_model.fit(X_train_proc, y_train_enc,epochs=20,batch_size=32,validation_data=(X_valid_proc, y_valid_enc)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPaS1JYaOAJj",
        "outputId": "cf2114a0-0ed2-4a9f-f6a5-68bc3397aa95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 0.3434 - val_accuracy: 0.8495 - val_loss: 0.3186\n",
            "Epoch 2/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3065 - val_accuracy: 0.8570 - val_loss: 0.3139\n",
            "Epoch 3/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.2954 - val_accuracy: 0.8551 - val_loss: 0.3104\n",
            "Epoch 4/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.2914 - val_accuracy: 0.8552 - val_loss: 0.3145\n",
            "Epoch 5/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.2853 - val_accuracy: 0.8578 - val_loss: 0.3122\n",
            "Epoch 6/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8726 - loss: 0.2764 - val_accuracy: 0.8543 - val_loss: 0.3203\n",
            "Epoch 7/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.2788 - val_accuracy: 0.8548 - val_loss: 0.3203\n",
            "Epoch 8/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8747 - loss: 0.2692 - val_accuracy: 0.8523 - val_loss: 0.3277\n",
            "Epoch 9/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.2576 - val_accuracy: 0.8483 - val_loss: 0.3349\n",
            "Epoch 10/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2522 - val_accuracy: 0.8515 - val_loss: 0.3449\n",
            "Epoch 11/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.2451 - val_accuracy: 0.8488 - val_loss: 0.3833\n",
            "Epoch 12/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.2344 - val_accuracy: 0.8463 - val_loss: 0.3757\n",
            "Epoch 13/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.2312 - val_accuracy: 0.8511 - val_loss: 0.4021\n",
            "Epoch 14/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8965 - loss: 0.2231 - val_accuracy: 0.8403 - val_loss: 0.4359\n",
            "Epoch 15/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.2161 - val_accuracy: 0.8409 - val_loss: 0.4558\n",
            "Epoch 16/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2145 - val_accuracy: 0.8480 - val_loss: 0.4858\n",
            "Epoch 17/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9023 - loss: 0.2053 - val_accuracy: 0.8481 - val_loss: 0.4822\n",
            "Epoch 18/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.1989 - val_accuracy: 0.8431 - val_loss: 0.5294\n",
            "Epoch 19/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.1927 - val_accuracy: 0.8448 - val_loss: 0.5714\n",
            "Epoch 20/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.1923 - val_accuracy: 0.8444 - val_loss: 0.5588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Do you see signs of overfitting?\n",
        "Yes,i see\n",
        "Training accuracy keeps increasing steadily (83% → 91%).\n",
        "\n",
        "Validation accuracy improves at first (~ 85%), but then stays flat or even drops slightly (~ 84%).\n",
        "This is sign of overfitting:\n",
        "the model continues to fit the training data better and better, but fails to improve on unseen validation data."
      ],
      "metadata": {
        "id": "BHQgVIGgPEso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#L2 regularization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "l2_model = Sequential()\n",
        "l2_model.add(Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train_proc.shape[1],)))\n",
        "l2_model.add(Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
        "l2_model.add(Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)))\n",
        "l2_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "l2_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "history_l2 = l2_model.fit(\n",
        "    X_train_proc, y_train_enc,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_valid_proc, y_valid_enc)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6IkJS8bPfSL",
        "outputId": "0479d1e6-f202-4ec6-db2f-246e073253fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 1.0971 - val_accuracy: 0.8424 - val_loss: 0.3843\n",
            "Epoch 2/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8509 - loss: 0.3679 - val_accuracy: 0.8487 - val_loss: 0.3644\n",
            "Epoch 3/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3578 - val_accuracy: 0.8537 - val_loss: 0.3548\n",
            "Epoch 4/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3500 - val_accuracy: 0.8523 - val_loss: 0.3546\n",
            "Epoch 5/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3491 - val_accuracy: 0.8484 - val_loss: 0.3583\n",
            "Epoch 6/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3459 - val_accuracy: 0.8517 - val_loss: 0.3549\n",
            "Epoch 7/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.3461 - val_accuracy: 0.8496 - val_loss: 0.3525\n",
            "Epoch 8/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.3418 - val_accuracy: 0.8534 - val_loss: 0.3470\n",
            "Epoch 9/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.3393 - val_accuracy: 0.8503 - val_loss: 0.3513\n",
            "Epoch 10/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.3426 - val_accuracy: 0.8540 - val_loss: 0.3439\n",
            "Epoch 11/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8521 - loss: 0.3402 - val_accuracy: 0.8515 - val_loss: 0.3483\n",
            "Epoch 12/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8554 - loss: 0.3359 - val_accuracy: 0.8500 - val_loss: 0.3480\n",
            "Epoch 13/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3421 - val_accuracy: 0.8480 - val_loss: 0.3505\n",
            "Epoch 14/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 0.3327 - val_accuracy: 0.8477 - val_loss: 0.3521\n",
            "Epoch 15/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.3427 - val_accuracy: 0.8518 - val_loss: 0.3418\n",
            "Epoch 16/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.3388 - val_accuracy: 0.8530 - val_loss: 0.3428\n",
            "Epoch 17/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.3370 - val_accuracy: 0.8514 - val_loss: 0.3446\n",
            "Epoch 18/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3329 - val_accuracy: 0.8529 - val_loss: 0.3404\n",
            "Epoch 19/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3338 - val_accuracy: 0.8492 - val_loss: 0.3477\n",
            "Epoch 20/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 0.3366 - val_accuracy: 0.8511 - val_loss: 0.3405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropout\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "dropout_model = Sequential()\n",
        "dropout_model.add(Dense(256, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "dropout_model.add(Dropout(0.5))   #drop 50% of the next nurens\n",
        "dropout_model.add(Dense(128, activation=\"relu\"))\n",
        "dropout_model.add(Dropout(0.5))\n",
        "dropout_model.add(Dense(64, activation=\"relu\"))\n",
        "dropout_model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "dropout_model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                     loss=\"binary_crossentropy\",\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "history_dropout = dropout_model.fit( X_train_proc, y_train_enc, epochs=20,batch_size=32,validation_data=(X_valid_proc, y_valid_enc)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiwtKPMDPtG9",
        "outputId": "7b607033-d06c-4d21-ed66-bbd38065f045"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.3681 - val_accuracy: 0.8581 - val_loss: 0.3144\n",
            "Epoch 2/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3173 - val_accuracy: 0.8538 - val_loss: 0.3174\n",
            "Epoch 3/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.3087 - val_accuracy: 0.8518 - val_loss: 0.3185\n",
            "Epoch 4/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 0.3028 - val_accuracy: 0.8579 - val_loss: 0.3137\n",
            "Epoch 5/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.3064 - val_accuracy: 0.8558 - val_loss: 0.3120\n",
            "Epoch 6/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3074 - val_accuracy: 0.8569 - val_loss: 0.3134\n",
            "Epoch 7/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3000 - val_accuracy: 0.8578 - val_loss: 0.3167\n",
            "Epoch 8/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.3042 - val_accuracy: 0.8563 - val_loss: 0.3173\n",
            "Epoch 9/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.3027 - val_accuracy: 0.8558 - val_loss: 0.3121\n",
            "Epoch 10/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.2913 - val_accuracy: 0.8545 - val_loss: 0.3127\n",
            "Epoch 11/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8633 - loss: 0.2938 - val_accuracy: 0.8540 - val_loss: 0.3144\n",
            "Epoch 12/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.2916 - val_accuracy: 0.8586 - val_loss: 0.3119\n",
            "Epoch 13/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.2928 - val_accuracy: 0.8563 - val_loss: 0.3131\n",
            "Epoch 14/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.2905 - val_accuracy: 0.8551 - val_loss: 0.3156\n",
            "Epoch 15/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.2914 - val_accuracy: 0.8555 - val_loss: 0.3142\n",
            "Epoch 16/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.2855 - val_accuracy: 0.8579 - val_loss: 0.3168\n",
            "Epoch 17/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.2904 - val_accuracy: 0.8579 - val_loss: 0.3131\n",
            "Epoch 18/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.2856 - val_accuracy: 0.8549 - val_loss: 0.3148\n",
            "Epoch 19/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8673 - loss: 0.2850 - val_accuracy: 0.8541 - val_loss: 0.3166\n",
            "Epoch 20/20\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.2813 - val_accuracy: 0.8548 - val_loss: 0.3188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before regularization:\n",
        "\n",
        " - Training accuracy => kept rising (83% → 91%).\n",
        "\n",
        "- Validation accuracy => peaked ~ 85% then dropped (~84%).\n",
        "\n",
        "- Validation loss →=> increased a lot\n",
        "\n",
        "\n",
        "With L2 regularization:\n",
        "\n",
        "Training accuracy: stayed ~85%.\n",
        "\n",
        "Validation accuracy: ~ 85% stable, doesn’t drop.\n",
        "\n",
        "Validation loss: much lower and flatter ~0.34–0.36, no big increase\n",
        "\n",
        "- =>L2 slowed down learning a bit, but kept train and val much closer.This means less overfitting.\n",
        "\n",
        "\n",
        "With Dropout:\n",
        "\n",
        "Training accuracy: lower than before because dropout forces the network to train with missing neurons\n",
        "\n",
        "Validation accuracy: usually more stable across epochs.\n",
        "\n",
        "- =>Dropout makes the model less likely to memorize patterns make it better generalization.\n",
        "\n",
        "in my opinion Both reduced overfitting compared to the unregularized model.\n",
        "But here L2 regularization was more effective because it kept validation accuracy stable and validation loss consistently low."
      ],
      "metadata": {
        "id": "4fB8PQj0SCHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train with Early Stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_es = Sequential()\n",
        "model_es.add(Dense(256, activation=\"relu\", input_shape=(X_train_proc.shape[1],)))\n",
        "model_es.add(Dense(128, activation=\"relu\"))\n",
        "model_es.add(Dense(64, activation=\"relu\"))\n",
        "model_es.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_es.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss=\"binary_crossentropy\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "history_es = model_es.fit(\n",
        "    X_train_proc, y_train_enc,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_valid_proc, y_valid_enc),\n",
        "    callbacks=[early_stop],\n",
        ")\n",
        "print(f\"Training stopped after {len(history_es.epoch)} epochs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDpdG4k-UG4f",
        "outputId": "5cda28ef-fcac-48c8-9ab8-9cc009f39c67"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3460 - val_accuracy: 0.8551 - val_loss: 0.3159\n",
            "Epoch 2/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3035 - val_accuracy: 0.8529 - val_loss: 0.3136\n",
            "Epoch 3/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3009 - val_accuracy: 0.8579 - val_loss: 0.3106\n",
            "Epoch 4/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.2931 - val_accuracy: 0.8537 - val_loss: 0.3135\n",
            "Epoch 5/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.2875 - val_accuracy: 0.8581 - val_loss: 0.3146\n",
            "Epoch 6/50\n",
            "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.2792 - val_accuracy: 0.8585 - val_loss: 0.3205\n",
            "Training stopped after 6 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparison of epochs and accuracy:\n",
        "\n",
        "**Without early stopping:**\n",
        "\n",
        "Training accuracy reached ~90%+.\n",
        "\n",
        "Validation accuracy peaked around epoch 5–7 (~85%), then dropped to ~84% or lower.\n",
        "\n",
        "Clear overfitting after epoch 7.\n",
        "\n",
        "**With early stopping :**\n",
        "\n",
        "Training stopped automatically after 6 epochs.\n",
        "\n",
        "Training accuracy: ~86.9%.\n",
        "\n",
        "Validation accuracy: ~85.8% (higher than the late epochs in the no-early-stopping run).\n",
        "\n",
        "Validation loss: stayed low (~0.31–0.32) instead of blowing up.\n",
        "\n",
        "### so early stopping saved ~14 epochs of wasted computation and gave better validation accuracy compared to training too long.\n",
        "\n",
        "\n",
        "#How early stopping prevents overfitting?\n",
        "\n",
        "It monitors validation loss\n",
        "When validation loss stops improving for a set number of epochs training stops.\n",
        "This prevents the model from continuing to learn the noise and quirks of the training data.\n",
        "\n",
        "By restoring the best weights(restore_best_weights=True) we keep the model at the point where it generalized best."
      ],
      "metadata": {
        "id": "2oApgOafWwSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection**\n",
        "1. What I learned\n",
        "\n",
        "**Optimizers**: They decide how the model updates its weights to reduce the loss.Some optimizers like Adam usually work better than others\n",
        "\n",
        "**Batch size**: Small batches make training very slower but can help the model learn better. Large batches train faster but might not generalize well.\n",
        "\n",
        "**Regularization**: Methods like early stopping Stops training when validation performance no longer improves. This saves time and prevents the model from getting worse on unseen data.L1,L2 remove irrelevant features or make their weight tend to zero, dropout remove random neurons to prevent the model from overfitting and to learn everytime with new values.\n",
        "\n",
        "Train/validation/test splits: Splitting the data ensures we train on one part, tune the model on another, and finally test on a fresh set to check real performance.\n",
        "#If I train a new deep learning model on tabular data, I would choose:\n",
        "\n",
        "**Optimizer**: Adam, because it’s fast and usually gives good results.\n",
        "\n",
        "**Batch size**: Medium size (like 32 or 64) for a balance between speed and accuracy.\n",
        "\n",
        "**Regularization**: Dropout or L2 regularization, to avoid overfitting.\n",
        "\n",
        "**Early stopping:** Yes, to stop training when validation loss stops improving.\n",
        "\n",
        "**Data splitting strategy:** Use 70% training, 15% validation, 15% test (or similar). This way I can tune the model on validation and still have a fresh test set."
      ],
      "metadata": {
        "id": "lkrQEaNwaHYg"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}